import nbformat as nbf

# Create a new notebook
nb = nbf.v4.new_notebook()

# Define the cells based on your structure
cells = [
    nbf.v4.new_markdown_cell(
        "# ðŸ§  Tunisian Dialect Hate Speech Detection with TunBERT\n\n"
        "This notebook demonstrates the fine-tuning and evaluation of the `AhmedBou/TuniBert` model on the T-HSAB dataset for classifying Tunisian dialect comments into:\n"
        "- Hate speech\n"
        "- Abusive language\n"
        "- Normal content\n\n"
        "All preprocessing, model loading, and evaluation logic is modularized in the `src/` directory."
    ),
    nbf.v4.new_code_cell(
        "!pip install transformers datasets tensorflow scikit-learn matplotlib seaborn"
    ),
    nbf.v4.new_code_cell(
        "from src.data_utils import load_and_clean_csv\n"
        "from src.model_utils import (\n"
        "    load_model_and_tokenizer,\n"
        "    tokenize_data,\n"
        "    create_tf_dataset,\n"
        "    compile_and_train\n"
        ")\n"
        "from src.evaluation import predict_classes, evaluate_model"
    ),
    nbf.v4.new_code_cell(
        "# Load and clean the dataset\n"
        "(X_train, X_test, y_train, y_test), label_encoder = load_and_clean_csv(\"data/thsab.csv\")"
    ),
    nbf.v4.new_code_cell(
        "# Load TunBERT model and tokenizer\n"
        "tokenizer, model = load_model_and_tokenizer()\n\n"
        "# Tokenize the texts\n"
        "train_encodings = tokenize_data(tokenizer, X_train)\n"
        "test_encodings = tokenize_data(tokenizer, X_test)"
    ),
    nbf.v4.new_code_cell(
        "# Create TensorFlow datasets\n"
        "train_ds = create_tf_dataset(train_encodings, y_train)\n"
        "test_ds = create_tf_dataset(test_encodings, y_test, shuffle=False)\n\n"
        "# Train the model\n"
        "history = compile_and_train(model, train_ds, test_ds)"
    ),
    nbf.v4.new_code_cell(
        "# Predict and evaluate\n"
        "y_pred = predict_classes(model, test_ds)\n"
        "evaluate_model(y_test, y_pred, label_encoder.classes_)"
    )
]

# Add the cells to the notebook
nb['cells'] = cells

# Save the notebook
with open("tunisian_hate_speech_detection.ipynb", "w", encoding="utf-8") as f:
    nbf.write(nb, f)
